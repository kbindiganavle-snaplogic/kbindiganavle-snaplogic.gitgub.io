


<!DOCTYPE html>
<html id="htmlId">
<head>
  <title>Coverage Report > AbstractInMemoryLookupCache</title>
  <style type="text/css">
    @import "../../css/coverage.css";
    @import "../../css/highlight-idea.css";
  </style>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script>
</head>

<body>
<div class="content">
<div class="breadCrumbs">
Current scope:     <a href="../../index.html">all classes</a>
    <span class="separator">|</span>
    <a href="../index.html">com.snaplogic.snaps.transform.inmemory</a>
</div>

<h1>Coverage Summary for Class: AbstractInMemoryLookupCache (com.snaplogic.snaps.transform.inmemory)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">AbstractInMemoryLookupCache</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/10)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/107)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<pre>
<div class="sourceCode" id="sourceCode"><i class="no-highlight">1</i>&nbsp;/*
<i class="no-highlight">2</i>&nbsp; * SnapLogic - Data Integration
<i class="no-highlight">3</i>&nbsp; *
<i class="no-highlight">4</i>&nbsp; * Copyright (C) 2017, SnapLogic, Inc.  All rights reserved.
<i class="no-highlight">5</i>&nbsp; *
<i class="no-highlight">6</i>&nbsp; * This program is licensed under the terms of
<i class="no-highlight">7</i>&nbsp; * the SnapLogic Commercial Subscription agreement.
<i class="no-highlight">8</i>&nbsp; *
<i class="no-highlight">9</i>&nbsp; * &quot;SnapLogic&quot; is a trademark of SnapLogic, Inc.
<i class="no-highlight">10</i>&nbsp; */
<i class="no-highlight">11</i>&nbsp;
<i class="no-highlight">12</i>&nbsp;package com.snaplogic.snaps.transform.inmemory;
<i class="no-highlight">13</i>&nbsp;
<i class="no-highlight">14</i>&nbsp;import com.esotericsoftware.kryo.Kryo;
<i class="no-highlight">15</i>&nbsp;import com.esotericsoftware.kryo.io.Input;
<i class="no-highlight">16</i>&nbsp;import com.esotericsoftware.kryo.io.Output;
<i class="no-highlight">17</i>&nbsp;import com.snaplogic.api.ExecutionException;
<i class="no-highlight">18</i>&nbsp;import com.snaplogic.snap.api.transform.Serializers;
<i class="no-highlight">19</i>&nbsp;import org.apache.commons.collections.keyvalue.MultiKey;
<i class="no-highlight">20</i>&nbsp;import org.apache.commons.io.FileUtils;
<i class="no-highlight">21</i>&nbsp;import org.apache.commons.math3.stat.descriptive.moment.Mean;
<i class="no-highlight">22</i>&nbsp;
<i class="no-highlight">23</i>&nbsp;import java.io.ByteArrayInputStream;
<i class="no-highlight">24</i>&nbsp;import java.io.IOException;
<i class="no-highlight">25</i>&nbsp;import java.io.InputStream;
<i class="no-highlight">26</i>&nbsp;import java.io.OutputStream;
<i class="no-highlight">27</i>&nbsp;import java.util.ArrayList;
<i class="no-highlight">28</i>&nbsp;import java.util.HashMap;
<i class="no-highlight">29</i>&nbsp;import java.util.List;
<i class="no-highlight">30</i>&nbsp;import java.util.Map;
<i class="no-highlight">31</i>&nbsp;import java.util.zip.GZIPInputStream;
<i class="no-highlight">32</i>&nbsp;import java.util.zip.GZIPOutputStream;
<i class="no-highlight">33</i>&nbsp;
<i class="no-highlight">34</i>&nbsp;public abstract class AbstractInMemoryLookupCache&lt;T&gt; {
<i class="no-highlight">35</i>&nbsp;
<i class="no-highlight">36</i>&nbsp;    protected static final int INIT_COLLECTION_SIZE = 4 * 1024;
<i class="no-highlight">37</i>&nbsp;
<b class="nc"><i class="no-highlight">38</i>&nbsp;    protected final ArrayDocsUtil arrayDocsUtil = new ArrayDocsUtil();</b>
<i class="no-highlight">39</i>&nbsp;
<i class="no-highlight">40</i>&nbsp;    /**
<i class="no-highlight">41</i>&nbsp;     * The field names used to build the lookup value keys
<i class="no-highlight">42</i>&nbsp;     */
<i class="no-highlight">43</i>&nbsp;    protected final String[] lookupKeyPaths;
<i class="no-highlight">44</i>&nbsp;
<i class="no-highlight">45</i>&nbsp;    /**
<i class="no-highlight">46</i>&nbsp;     * The field names used to build keys for the documents that will perform a lookup
<i class="no-highlight">47</i>&nbsp;     */
<i class="no-highlight">48</i>&nbsp;    protected final String[] matchKeyPaths;
<i class="no-highlight">49</i>&nbsp;
<i class="no-highlight">50</i>&nbsp;    /**
<i class="no-highlight">51</i>&nbsp;     * The pages of serialized lookup documents. Documents are organized by
<i class="no-highlight">52</i>&nbsp;     * key in each page.
<i class="no-highlight">53</i>&nbsp;     */
<b class="nc"><i class="no-highlight">54</i>&nbsp;    private final List&lt;byte[]&gt; lookupPages = new ArrayList&lt;&gt;(INIT_COLLECTION_SIZE);</b>
<i class="no-highlight">55</i>&nbsp;
<i class="no-highlight">56</i>&nbsp;    /**
<i class="no-highlight">57</i>&nbsp;     * The lookup documents that have not been added to a page yet. Documents are organized by document key.
<i class="no-highlight">58</i>&nbsp;     */
<b class="nc"><i class="no-highlight">59</i>&nbsp;    protected final Map&lt;Object, T&gt; unprocessedLookupDocs = new HashMap&lt;&gt;(INIT_COLLECTION_SIZE);</b>
<i class="no-highlight">60</i>&nbsp;
<i class="no-highlight">61</i>&nbsp;    /**
<i class="no-highlight">62</i>&nbsp;     * The number of documents that have not been processed and need to be added to a page.
<i class="no-highlight">63</i>&nbsp;     */
<b class="nc"><i class="no-highlight">64</i>&nbsp;    protected int unprocessedLookupDocsCount = 0;</b>
<i class="no-highlight">65</i>&nbsp;
<i class="no-highlight">66</i>&nbsp;    /**
<i class="no-highlight">67</i>&nbsp;     * Defines if compression should be used or not.
<i class="no-highlight">68</i>&nbsp;     */
<i class="no-highlight">69</i>&nbsp;    private boolean useCompression;
<i class="no-highlight">70</i>&nbsp;
<i class="no-highlight">71</i>&nbsp;    /**
<i class="no-highlight">72</i>&nbsp;     * Defines enabling compression should be considered. The cache starts with compression disabled and
<i class="no-highlight">73</i>&nbsp;     * automatically enables it for larger caches of documents when it will size space.
<i class="no-highlight">74</i>&nbsp;     */
<b class="nc"><i class="no-highlight">75</i>&nbsp;    private boolean checkCompression = true;</b>
<i class="no-highlight">76</i>&nbsp;
<i class="no-highlight">77</i>&nbsp;    /**
<i class="no-highlight">78</i>&nbsp;     * The number of documents in a page. This is used to estimate how many documents are in a page of a given size
<i class="no-highlight">79</i>&nbsp;     * so that a byte array that is too big is not created.
<i class="no-highlight">80</i>&nbsp;     */
<b class="nc"><i class="no-highlight">81</i>&nbsp;    private int documentsPerPage = 4;</b>
<i class="no-highlight">82</i>&nbsp;
<i class="no-highlight">83</i>&nbsp;    /**
<i class="no-highlight">84</i>&nbsp;     * The ideal page size. The number of documents are tweaked to achieve this.
<i class="no-highlight">85</i>&nbsp;     */
<i class="no-highlight">86</i>&nbsp;    private static final int IDEAL_BUFFER_SIZE = 4 * 1024;
<i class="no-highlight">87</i>&nbsp;
<i class="no-highlight">88</i>&nbsp;    /**
<i class="no-highlight">89</i>&nbsp;     * Stream used to create pages of serialized documents. This is reused to reduce the amount of byte arrays
<i class="no-highlight">90</i>&nbsp;     * allocated.
<i class="no-highlight">91</i>&nbsp;     */
<b class="nc"><i class="no-highlight">92</i>&nbsp;    private final org.apache.commons.io.output.ByteArrayOutputStream baOut =</b>
<i class="no-highlight">93</i>&nbsp;            new org.apache.commons.io.output.ByteArrayOutputStream();
<i class="no-highlight">94</i>&nbsp;
<i class="no-highlight">95</i>&nbsp;    /**
<i class="no-highlight">96</i>&nbsp;     * This is reused to avoid memory allocations for each {@link Output} and {@link Input} object.
<i class="no-highlight">97</i>&nbsp;     */
<b class="nc"><i class="no-highlight">98</i>&nbsp;    private final byte[] kryoBuffer = new byte[IDEAL_BUFFER_SIZE];</b>
<i class="no-highlight">99</i>&nbsp;
<i class="no-highlight">100</i>&nbsp;    /**
<i class="no-highlight">101</i>&nbsp;     * Serializes and deserializes pages of documents. This preserves the document field value types without needing
<i class="no-highlight">102</i>&nbsp;     * a schema and is much faster than ObjectOutputStream and ObjectInputStream.
<i class="no-highlight">103</i>&nbsp;     */
<b class="nc"><i class="no-highlight">104</i>&nbsp;    private final Kryo serializer = Serializers.kryo();</b>
<i class="no-highlight">105</i>&nbsp;
<i class="no-highlight">106</i>&nbsp;    /**
<i class="no-highlight">107</i>&nbsp;     * The average page size. This is used to allocated the buffer for the next page and avoid having to grow a buffer.
<i class="no-highlight">108</i>&nbsp;     */
<b class="nc"><i class="no-highlight">109</i>&nbsp;    private final Mean pageSizeMean = new Mean();</b>
<i class="no-highlight">110</i>&nbsp;
<i class="no-highlight">111</i>&nbsp;    /**
<i class="no-highlight">112</i>&nbsp;     * The average number of documents per page.
<i class="no-highlight">113</i>&nbsp;     */
<b class="nc"><i class="no-highlight">114</i>&nbsp;    private final Mean documentsPerPageMean = new Mean();</b>
<i class="no-highlight">115</i>&nbsp;
<i class="no-highlight">116</i>&nbsp;    /**
<i class="no-highlight">117</i>&nbsp;     * The total size of all pages. This is used to determine if compression should be enabled.
<i class="no-highlight">118</i>&nbsp;     */
<b class="nc"><i class="no-highlight">119</i>&nbsp;    private long totalSize = 0;</b>
<i class="no-highlight">120</i>&nbsp;
<i class="no-highlight">121</i>&nbsp;    /**
<i class="no-highlight">122</i>&nbsp;     * The maximum cache size before compression is considered.
<i class="no-highlight">123</i>&nbsp;     */
<b class="nc"><i class="no-highlight">124</i>&nbsp;    private final long MAX_UNCOMPRESSED = 1024 * 1024 * 1024; //1GB</b>
<i class="no-highlight">125</i>&nbsp;
<i class="no-highlight">126</i>&nbsp;    /**
<i class="no-highlight">127</i>&nbsp;     * The first page index that compression was used on. When compression is enabled the cache does not go back
<i class="no-highlight">128</i>&nbsp;     * and compress the documents to save time.
<i class="no-highlight">129</i>&nbsp;     */
<i class="no-highlight">130</i>&nbsp;    private int firstCompressionPageIndex;
<i class="no-highlight">131</i>&nbsp;
<i class="no-highlight">132</i>&nbsp;    /**
<i class="no-highlight">133</i>&nbsp;     * Creates a new lookup cache
<i class="no-highlight">134</i>&nbsp;     *
<i class="no-highlight">135</i>&nbsp;     * @param joinPaths The field names to build the key for the lookup and match documents. The key is the match
<i class="no-highlight">136</i>&nbsp;     *                  document field path and the value is the corresponding lookup document field path.
<i class="no-highlight">137</i>&nbsp;     */
<b class="nc"><i class="no-highlight">138</i>&nbsp;    protected AbstractInMemoryLookupCache(Map&lt;String, String&gt; joinPaths) {</b>
<b class="nc"><i class="no-highlight">139</i>&nbsp;        matchKeyPaths = new String[joinPaths.size()];</b>
<b class="nc"><i class="no-highlight">140</i>&nbsp;        lookupKeyPaths = new String[joinPaths.size()];</b>
<i class="no-highlight">141</i>&nbsp;
<b class="nc"><i class="no-highlight">142</i>&nbsp;        int index = 0;</b>
<b class="nc"><i class="no-highlight">143</i>&nbsp;        for (Map.Entry&lt;String, String&gt; joinPath : joinPaths.entrySet()) {</b>
<b class="nc"><i class="no-highlight">144</i>&nbsp;            matchKeyPaths[index] = joinPath.getKey();</b>
<b class="nc"><i class="no-highlight">145</i>&nbsp;            lookupKeyPaths[index] = joinPath.getValue();</b>
<b class="nc"><i class="no-highlight">146</i>&nbsp;            ++index;</b>
<b class="nc"><i class="no-highlight">147</i>&nbsp;        }</b>
<i class="no-highlight">148</i>&nbsp;    }
<i class="no-highlight">149</i>&nbsp;
<i class="no-highlight">150</i>&nbsp;    /**
<i class="no-highlight">151</i>&nbsp;     * Adds a lookup document to the unprocessed queue. This should add the document to
<i class="no-highlight">152</i>&nbsp;     * {@link AbstractInMemoryLookupCache#unprocessedLookupDocs} and update
<i class="no-highlight">153</i>&nbsp;     * {@link AbstractInMemoryLookupCache#unprocessedLookupDocsCount} so the unprocessed cache is not iterated over
<i class="no-highlight">154</i>&nbsp;     * for each document.
<i class="no-highlight">155</i>&nbsp;     * @param documentKey
<i class="no-highlight">156</i>&nbsp;     * @param document
<i class="no-highlight">157</i>&nbsp;     */
<i class="no-highlight">158</i>&nbsp;    protected abstract void addLookupDocToUnprocessed(Object documentKey, Map&lt;String, Object&gt; document);
<i class="no-highlight">159</i>&nbsp;
<i class="no-highlight">160</i>&nbsp;    /**
<i class="no-highlight">161</i>&nbsp;     * Adds a document to the lookup cache
<i class="no-highlight">162</i>&nbsp;     * @param document
<i class="no-highlight">163</i>&nbsp;     */
<i class="no-highlight">164</i>&nbsp;    public void addLookupDoc(Map&lt;String, Object&gt; document) {
<b class="nc"><i class="no-highlight">165</i>&nbsp;        Object documentKey = buildDocumentKey(lookupKeyPaths, document);</b>
<b class="nc"><i class="no-highlight">166</i>&nbsp;        addLookupDocToUnprocessed(documentKey, document);</b>
<i class="no-highlight">167</i>&nbsp;
<i class="no-highlight">168</i>&nbsp;        //See if unprocessed collections is full
<b class="nc"><i class="no-highlight">169</i>&nbsp;        if (unprocessedLookupDocsCount &gt;= documentsPerPage) {</b>
<b class="nc"><i class="no-highlight">170</i>&nbsp;            createPage();</b>
<i class="no-highlight">171</i>&nbsp;        }
<i class="no-highlight">172</i>&nbsp;    }
<i class="no-highlight">173</i>&nbsp;
<i class="no-highlight">174</i>&nbsp;    /**
<i class="no-highlight">175</i>&nbsp;     * Adds a new page pointer to the list of page pointers.
<i class="no-highlight">176</i>&nbsp;     * @param documentKey
<i class="no-highlight">177</i>&nbsp;     * @param location The location of the documents
<i class="no-highlight">178</i>&nbsp;     */
<i class="no-highlight">179</i>&nbsp;    protected abstract void addPagePointer(Object documentKey, int[] location);
<i class="no-highlight">180</i>&nbsp;
<i class="no-highlight">181</i>&nbsp;    /**
<i class="no-highlight">182</i>&nbsp;     * Creates a new documents page from the unprocessed documents cache.
<i class="no-highlight">183</i>&nbsp;     */
<i class="no-highlight">184</i>&nbsp;    private void createPage() {
<b class="nc"><i class="no-highlight">185</i>&nbsp;        int pageIndex = lookupPages.size();</b>
<i class="no-highlight">186</i>&nbsp;
<i class="no-highlight">187</i>&nbsp;        //Populate each bucket in the page
<b class="nc"><i class="no-highlight">188</i>&nbsp;        for (Map.Entry&lt;Object, T&gt; entry : unprocessedLookupDocs.entrySet()) {</b>
<i class="no-highlight">189</i>&nbsp;            //Create a reference to the location for the key
<b class="nc"><i class="no-highlight">190</i>&nbsp;            int thisBucket = baOut.size();</b>
<b class="nc"><i class="no-highlight">191</i>&nbsp;            int[] location = new int[]{pageIndex, thisBucket};</b>
<b class="nc"><i class="no-highlight">192</i>&nbsp;            addPagePointer(entry.getKey(), location);</b>
<i class="no-highlight">193</i>&nbsp;
<i class="no-highlight">194</i>&nbsp;            //Write the documents to the page
<b class="nc"><i class="no-highlight">195</i>&nbsp;            try (OutputStream stream = useCompression ? new GZIPOutputStream(baOut) : baOut;</b>
<b class="nc"><i class="no-highlight">196</i>&nbsp;                 Output output = new Output(kryoBuffer)) {</b>
<b class="nc"><i class="no-highlight">197</i>&nbsp;                output.setOutputStream(stream);</b>
<b class="nc"><i class="no-highlight">198</i>&nbsp;                serializer.writeObject(output, entry.getValue());</b>
<b class="nc"><i class="no-highlight">199</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i class="no-highlight">200</i>&nbsp;                throw new ExecutionException(e, &quot;Could not serialize lookup page.&quot;);</b>
<b class="nc"><i class="no-highlight">201</i>&nbsp;            }</b>
<b class="nc"><i class="no-highlight">202</i>&nbsp;        }</b>
<i class="no-highlight">203</i>&nbsp;
<i class="no-highlight">204</i>&nbsp;        //Add the page to the page cache
<b class="nc"><i class="no-highlight">205</i>&nbsp;        byte[] pageCompressed = baOut.toByteArray();</b>
<b class="nc"><i class="no-highlight">206</i>&nbsp;        baOut.reset();</b>
<b class="nc"><i class="no-highlight">207</i>&nbsp;        lookupPages.add(pageCompressed);</b>
<b class="nc"><i class="no-highlight">208</i>&nbsp;        totalSize += pageCompressed.length;</b>
<i class="no-highlight">209</i>&nbsp;
<i class="no-highlight">210</i>&nbsp;        //Check if compression should be enabled
<b class="nc"><i class="no-highlight">211</i>&nbsp;        checkCompression(pageCompressed.length, unprocessedLookupDocs);</b>
<i class="no-highlight">212</i>&nbsp;
<i class="no-highlight">213</i>&nbsp;        //update page stats
<b class="nc"><i class="no-highlight">214</i>&nbsp;        pageSizeMean.increment(pageCompressed.length);</b>
<b class="nc"><i class="no-highlight">215</i>&nbsp;        documentsPerPageMean.increment(unprocessedLookupDocsCount);</b>
<i class="no-highlight">216</i>&nbsp;
<i class="no-highlight">217</i>&nbsp;        //Clear processed documents
<b class="nc"><i class="no-highlight">218</i>&nbsp;        unprocessedLookupDocs.clear();</b>
<b class="nc"><i class="no-highlight">219</i>&nbsp;        unprocessedLookupDocsCount = 0;</b>
<i class="no-highlight">220</i>&nbsp;
<i class="no-highlight">221</i>&nbsp;        //adjust page size
<i class="no-highlight">222</i>&nbsp;        //the purpose of this is to prevent huge memory allocations, but also make sure page sizes do not get
<i class="no-highlight">223</i>&nbsp;        //too small and slow down page traversal when searching for matching documents.
<b class="nc"><i class="no-highlight">224</i>&nbsp;        double pageSizeMeanCur = (int)pageSizeMean.getResult();</b>
<b class="nc"><i class="no-highlight">225</i>&nbsp;        if (pageSizeMeanCur &gt; IDEAL_BUFFER_SIZE) {</b>
<i class="no-highlight">226</i>&nbsp;            //page size is too big. reduce the number of documents per page.
<b class="nc"><i class="no-highlight">227</i>&nbsp;            int newPageSize = (int)Math.floor(documentsPerPage * IDEAL_BUFFER_SIZE / pageSizeMeanCur);</b>
<b class="nc"><i class="no-highlight">228</i>&nbsp;            documentsPerPage = Math.max(newPageSize, 1);</b>
<b class="nc"><i class="no-highlight">229</i>&nbsp;        } else if (pageSizeMeanCur &lt; IDEAL_BUFFER_SIZE) {</b>
<i class="no-highlight">230</i>&nbsp;            //page size is too small. increase documents per page
<b class="nc"><i class="no-highlight">231</i>&nbsp;            documentsPerPage = (int)Math.ceil(documentsPerPage * IDEAL_BUFFER_SIZE / pageSizeMeanCur);</b>
<i class="no-highlight">232</i>&nbsp;        }
<i class="no-highlight">233</i>&nbsp;    }
<i class="no-highlight">234</i>&nbsp;
<i class="no-highlight">235</i>&nbsp;    private void checkCompression(int uncompressedLength, Map&lt;Object, T&gt; documents) {
<b class="nc"><i class="no-highlight">236</i>&nbsp;        if (checkCompression &amp;&amp; totalSize &gt; MAX_UNCOMPRESSED) {</b>
<i class="no-highlight">237</i>&nbsp;            //Only check if compression should be enabled once
<b class="nc"><i class="no-highlight">238</i>&nbsp;            checkCompression = false;</b>
<i class="no-highlight">239</i>&nbsp;
<b class="nc"><i class="no-highlight">240</i>&nbsp;            if (shouldCompress(uncompressedLength, documents)) {</b>
<b class="nc"><i class="no-highlight">241</i>&nbsp;                useCompression = true;</b>
<b class="nc"><i class="no-highlight">242</i>&nbsp;                firstCompressionPageIndex = lookupPages.size();</b>
<i class="no-highlight">243</i>&nbsp;            }
<i class="no-highlight">244</i>&nbsp;        }
<i class="no-highlight">245</i>&nbsp;    }
<i class="no-highlight">246</i>&nbsp;
<i class="no-highlight">247</i>&nbsp;    private boolean shouldCompress(int uncompressedLength, Map&lt;Object, T&gt; documents) {
<i class="no-highlight">248</i>&nbsp;        //compress documents
<b class="nc"><i class="no-highlight">249</i>&nbsp;        for (Map.Entry&lt;Object, T&gt; entry : documents.entrySet()) {</b>
<i class="no-highlight">250</i>&nbsp;            //Write the documents to the page
<b class="nc"><i class="no-highlight">251</i>&nbsp;            try (OutputStream stream = new GZIPOutputStream(baOut);</b>
<b class="nc"><i class="no-highlight">252</i>&nbsp;                 Output output = new Output(kryoBuffer)) {</b>
<b class="nc"><i class="no-highlight">253</i>&nbsp;                output.setOutputStream(stream);</b>
<b class="nc"><i class="no-highlight">254</i>&nbsp;                serializer.writeObject(output, entry.getValue());</b>
<b class="nc"><i class="no-highlight">255</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i class="no-highlight">256</i>&nbsp;                throw new ExecutionException(e, &quot;Could not serialize lookup page while checking compression.&quot;);</b>
<b class="nc"><i class="no-highlight">257</i>&nbsp;            }</b>
<b class="nc"><i class="no-highlight">258</i>&nbsp;        }</b>
<i class="no-highlight">259</i>&nbsp;
<b class="nc"><i class="no-highlight">260</i>&nbsp;        boolean shouldCompress = baOut.size() &lt; uncompressedLength;</b>
<b class="nc"><i class="no-highlight">261</i>&nbsp;        baOut.reset();</b>
<i class="no-highlight">262</i>&nbsp;
<b class="nc"><i class="no-highlight">263</i>&nbsp;        return shouldCompress;</b>
<i class="no-highlight">264</i>&nbsp;    }
<i class="no-highlight">265</i>&nbsp;
<i class="no-highlight">266</i>&nbsp;    /**
<i class="no-highlight">267</i>&nbsp;     * Finds a single document in the lookup cache with a matching key
<i class="no-highlight">268</i>&nbsp;     *
<i class="no-highlight">269</i>&nbsp;     * @param document The document to match in the lookup
<i class="no-highlight">270</i>&nbsp;     * @return The first document found with a matching key. If no match is found then null is returned.
<i class="no-highlight">271</i>&nbsp;     */
<i class="no-highlight">272</i>&nbsp;    public abstract Map&lt;String, Object&gt; getSingleMatch(Map&lt;String, Object&gt; document);
<i class="no-highlight">273</i>&nbsp;
<i class="no-highlight">274</i>&nbsp;    /**
<i class="no-highlight">275</i>&nbsp;     * Finds all documents in the lookup cache with a matching key
<i class="no-highlight">276</i>&nbsp;     *
<i class="no-highlight">277</i>&nbsp;     * @param document The document to match in the lookup
<i class="no-highlight">278</i>&nbsp;     * @return A list of matching documents. If no documents are found then null is returned.
<i class="no-highlight">279</i>&nbsp;     */
<i class="no-highlight">280</i>&nbsp;    public abstract List&lt;Map&lt;String, Object&gt;&gt; getMatches(Map&lt;String, Object&gt; document);
<i class="no-highlight">281</i>&nbsp;
<i class="no-highlight">282</i>&nbsp;    /**
<i class="no-highlight">283</i>&nbsp;     * Builds a key for a document. If there is only one key then the key object is returned. If there are multiple
<i class="no-highlight">284</i>&nbsp;     * keys then a {@link MultiKey} object is returned. This is a memory optimization.
<i class="no-highlight">285</i>&nbsp;     *
<i class="no-highlight">286</i>&nbsp;     * @param keyPaths   The field paths to the key values
<i class="no-highlight">287</i>&nbsp;     * @param document The document to build a key for
<i class="no-highlight">288</i>&nbsp;     * @return The key for the document.
<i class="no-highlight">289</i>&nbsp;     */
<i class="no-highlight">290</i>&nbsp;    protected static Object buildDocumentKey(String[] keyPaths, Map&lt;String, Object&gt; document) {
<b class="nc"><i class="no-highlight">291</i>&nbsp;        if (keyPaths.length == 1) {</b>
<b class="nc"><i class="no-highlight">292</i>&nbsp;            Object keyValue = document.get(keyPaths[0]);</b>
<b class="nc"><i class="no-highlight">293</i>&nbsp;            if (keyValue instanceof Number) {</b>
<b class="nc"><i class="no-highlight">294</i>&nbsp;                keyValue = BigDecimalKey.create((Number)keyValue);</b>
<i class="no-highlight">295</i>&nbsp;            }
<i class="no-highlight">296</i>&nbsp;
<b class="nc"><i class="no-highlight">297</i>&nbsp;            return keyValue;</b>
<i class="no-highlight">298</i>&nbsp;        } else {
<b class="nc"><i class="no-highlight">299</i>&nbsp;            Object[] keyValues = new Object[keyPaths.length];</b>
<b class="nc"><i class="no-highlight">300</i>&nbsp;            for (int i = 0; i &lt; keyPaths.length; i++) {</b>
<b class="nc"><i class="no-highlight">301</i>&nbsp;                String keyPath = keyPaths[i];</b>
<b class="nc"><i class="no-highlight">302</i>&nbsp;                Object keyValue = document.get(keyPath);</b>
<b class="nc"><i class="no-highlight">303</i>&nbsp;                if (keyValue instanceof Number) {</b>
<b class="nc"><i class="no-highlight">304</i>&nbsp;                    keyValue = BigDecimalKey.create((Number) keyValue);</b>
<i class="no-highlight">305</i>&nbsp;                }
<b class="nc"><i class="no-highlight">306</i>&nbsp;                keyValues[i] = keyValue;</b>
<i class="no-highlight">307</i>&nbsp;            }
<i class="no-highlight">308</i>&nbsp;
<b class="nc"><i class="no-highlight">309</i>&nbsp;            return new MultiKey(keyValues);</b>
<i class="no-highlight">310</i>&nbsp;        }
<i class="no-highlight">311</i>&nbsp;    }
<i class="no-highlight">312</i>&nbsp;
<i class="no-highlight">313</i>&nbsp;    /**
<i class="no-highlight">314</i>&nbsp;     * Gets a documents bucket from a page.
<i class="no-highlight">315</i>&nbsp;     *
<i class="no-highlight">316</i>&nbsp;     * @param pageLocation The location in the page where the documents exist
<i class="no-highlight">317</i>&nbsp;     * @param clazz The type of object to deserialize the bucket to
<i class="no-highlight">318</i>&nbsp;     * @return The documents. If there is one document this will be an Object[] representing a single document.
<i class="no-highlight">319</i>&nbsp;     * If there are multiple documents then this is a Object[][] where each entry is a document.
<i class="no-highlight">320</i>&nbsp;     */
<i class="no-highlight">321</i>&nbsp;    protected &lt;T&gt; T getBucket(int[] pageLocation, Class&lt;T&gt; clazz) {
<b class="nc"><i class="no-highlight">322</i>&nbsp;        int pageIndex = pageLocation[0];</b>
<b class="nc"><i class="no-highlight">323</i>&nbsp;        int bucketIndex = pageLocation[1];</b>
<b class="nc"><i class="no-highlight">324</i>&nbsp;        byte[] pageCompressed = lookupPages.get(pageIndex);</b>
<i class="no-highlight">325</i>&nbsp;
<b class="nc"><i class="no-highlight">326</i>&nbsp;        ByteArrayInputStream baIn = new ByteArrayInputStream(pageCompressed);</b>
<b class="nc"><i class="no-highlight">327</i>&nbsp;        if (baIn.skip(bucketIndex) != bucketIndex) {</b>
<b class="nc"><i class="no-highlight">328</i>&nbsp;            throw new ExecutionException(String.format(&quot;Corrupt page byte array at index %s bucket index %s. &quot; +</b>
<b class="nc"><i class="no-highlight">329</i>&nbsp;                    &quot;The stream ended before the bucket index was reached.&quot;, pageIndex, bucketIndex));</b>
<i class="no-highlight">330</i>&nbsp;        }
<i class="no-highlight">331</i>&nbsp;
<b class="nc"><i class="no-highlight">332</i>&nbsp;        try (InputStream stream = useCompression &amp;&amp; pageIndex &gt;= firstCompressionPageIndex ?</b>
<b class="nc"><i class="no-highlight">333</i>&nbsp;                new GZIPInputStream(baIn) : baIn;</b>
<b class="nc"><i class="no-highlight">334</i>&nbsp;             Input input = new Input(kryoBuffer)) {</b>
<b class="nc"><i class="no-highlight">335</i>&nbsp;            input.setInputStream(stream);</b>
<b class="nc"><i class="no-highlight">336</i>&nbsp;            return serializer.readObject(input, clazz);</b>
<i class="no-highlight">337</i>&nbsp;
<b class="nc"><i class="no-highlight">338</i>&nbsp;        } catch (IOException e) {</b>
<b class="nc"><i class="no-highlight">339</i>&nbsp;            throw new ExecutionException(e, String.format(&quot;Could not deserialize page index %s bucket index %s&quot;,</b>
<b class="nc"><i class="no-highlight">340</i>&nbsp;                    pageIndex, bucketIndex));</b>
<i class="no-highlight">341</i>&nbsp;        }
<i class="no-highlight">342</i>&nbsp;    }
<i class="no-highlight">343</i>&nbsp;
<i class="no-highlight">344</i>&nbsp;    public abstract int uniqueKeysSize();
<i class="no-highlight">345</i>&nbsp;
<i class="no-highlight">346</i>&nbsp;    /**
<i class="no-highlight">347</i>&nbsp;     * This flushes unprocessed lookup documents to a new page. This should be called when the client is done
<i class="no-highlight">348</i>&nbsp;     * adding lookup documents, before starting to search for matching documents.
<i class="no-highlight">349</i>&nbsp;     */
<i class="no-highlight">350</i>&nbsp;    public void flush() {
<b class="nc"><i class="no-highlight">351</i>&nbsp;        if (unprocessedLookupDocsCount &gt; 0) {</b>
<b class="nc"><i class="no-highlight">352</i>&nbsp;            createPage();</b>
<i class="no-highlight">353</i>&nbsp;        }
<i class="no-highlight">354</i>&nbsp;    }
<i class="no-highlight">355</i>&nbsp;
<i class="no-highlight">356</i>&nbsp;    @Override
<i class="no-highlight">357</i>&nbsp;    public String toString() {
<i class="no-highlight">358</i>&nbsp;
<b class="nc"><i class="no-highlight">359</i>&nbsp;        return String.format(&quot;Using compression: %s, Total cache size: %s, &quot; +</b>
<i class="no-highlight">360</i>&nbsp;                        &quot;Total pages: %d, Average page size: %d bytes/page &quot; +
<i class="no-highlight">361</i>&nbsp;                        &quot;%d documents/page, Unique document keys: %d, Unique sets of field names: %d&quot;,
<b class="nc"><i class="no-highlight">362</i>&nbsp;                useCompression, FileUtils.byteCountToDisplaySize(totalSize),</b>
<b class="nc"><i class="no-highlight">363</i>&nbsp;                lookupPages.size(), (int) pageSizeMean.getResult(),</b>
<b class="nc"><i class="no-highlight">364</i>&nbsp;                (int) documentsPerPageMean.getResult(), uniqueKeysSize(),</b>
<b class="nc"><i class="no-highlight">365</i>&nbsp;                arrayDocsUtil.getFieldNameSetsSize());</b>
<i class="no-highlight">366</i>&nbsp;    }
<i class="no-highlight">367</i>&nbsp;
<i class="no-highlight">368</i>&nbsp;    public static AbstractInMemoryLookupCache create(boolean singleLookup, Map&lt;String, String&gt; joinPaths) {
<b class="nc"><i class="no-highlight">369</i>&nbsp;        return singleLookup ? new SingleInMemoryLookupCache(joinPaths) : new MultipleInMemoryLookupCache(joinPaths);</b>
<i class="no-highlight">370</i>&nbsp;    }
<i class="no-highlight">371</i>&nbsp;}
</div>
</pre>
</div>

<script type="text/javascript">
(function() {
    var msie = false, msie9 = false;
    /*@cc_on
      msie = true;
      @if (@_jscript_version >= 9)
        msie9 = true;
      @end
    @*/

    if (!msie || msie && msie9) {
        var codeBlock = document.getElementById('sourceCode');

        if (codeBlock) {
            hljs.highlightBlock(codeBlock);
        }
    }
})();
</script>

<div class="footer">
    
    <div style="float:right;">generated on 2024-01-19 15:49</div>
</div>
</body>
</html>
