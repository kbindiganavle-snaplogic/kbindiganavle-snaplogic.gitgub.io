


<!DOCTYPE html>
<html id="htmlId">
<head>
  <title>Coverage Report > ParquetReadingParser</title>
  <style type="text/css">
    @import "../../css/coverage.css";
    @import "../../css/highlight-idea.css";
  </style>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script>
</head>

<body>
<div class="content">
<div class="breadCrumbs">
Current scope:     <a href="../../index.html">all classes</a>
    <span class="separator">|</span>
    <a href="../index.html">com.snaplogic.snaps.hadoop</a>
</div>

<h1>Coverage Summary for Class: ParquetReadingParser (com.snaplogic.snaps.hadoop)</h1>

<table class="coverageStats">

<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">ParquetReadingParser</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/17)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/214)
  </span>
</td>
</tr>
  <tr>
    <td class="name">ParquetReadingParser$1</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/2)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/7)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">ParquetReadingParser$1$1</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">ParquetReadingParser$1$2</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
  </tr>
  <tr>
    <td class="name">ParquetReadingParser$PrivilegedKerberizedParquetReader</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/3)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/23)
  </span>
</td>
  </tr>
<tr>
  <td class="name"><strong>Total</strong></td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/24)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/246)
  </span>
</td>
</tr>
</table>

<br/>
<br/>


<pre>
<div class="sourceCode" id="sourceCode"><i class="no-highlight">1</i>&nbsp;/*
<i class="no-highlight">2</i>&nbsp; * SnapLogic - Data Integration
<i class="no-highlight">3</i>&nbsp; *
<i class="no-highlight">4</i>&nbsp; * Copyright (C) 2015, SnapLogic, Inc.  All rights reserved.
<i class="no-highlight">5</i>&nbsp; *
<i class="no-highlight">6</i>&nbsp; * This program is licensed under the terms of
<i class="no-highlight">7</i>&nbsp; * the SnapLogic Commercial Subscription agreement.
<i class="no-highlight">8</i>&nbsp; *
<i class="no-highlight">9</i>&nbsp; * &quot;SnapLogic&quot; is a trademark of SnapLogic, Inc.
<i class="no-highlight">10</i>&nbsp; */
<i class="no-highlight">11</i>&nbsp;package com.snaplogic.snaps.hadoop;
<i class="no-highlight">12</i>&nbsp;
<i class="no-highlight">13</i>&nbsp;import com.amazonaws.AmazonClientException;
<i class="no-highlight">14</i>&nbsp;import com.google.common.annotations.VisibleForTesting;
<i class="no-highlight">15</i>&nbsp;import com.google.inject.AbstractModule;
<i class="no-highlight">16</i>&nbsp;import com.google.inject.Inject;
<i class="no-highlight">17</i>&nbsp;import com.google.inject.Key;
<i class="no-highlight">18</i>&nbsp;import com.google.inject.Module;
<i class="no-highlight">19</i>&nbsp;import com.google.inject.Scopes;
<i class="no-highlight">20</i>&nbsp;import com.google.inject.TypeLiteral;
<i class="no-highlight">21</i>&nbsp;import com.snaplogic.account.api.Account;
<i class="no-highlight">22</i>&nbsp;import com.snaplogic.account.api.capabilities.Accounts;
<i class="no-highlight">23</i>&nbsp;import com.snaplogic.account.api.capabilities.MultiAccountBinding;
<i class="no-highlight">24</i>&nbsp;import com.snaplogic.api.ConfigurationException;
<i class="no-highlight">25</i>&nbsp;import com.snaplogic.api.ExecutionException;
<i class="no-highlight">26</i>&nbsp;import com.snaplogic.common.SnapType;
<i class="no-highlight">27</i>&nbsp;import com.snaplogic.common.jsonpath.InvalidPathException;
<i class="no-highlight">28</i>&nbsp;import com.snaplogic.common.jsonpath.JsonPath;
<i class="no-highlight">29</i>&nbsp;import com.snaplogic.common.properties.SnapProperty;
<i class="no-highlight">30</i>&nbsp;import com.snaplogic.common.properties.builders.PropertyBuilder;
<i class="no-highlight">31</i>&nbsp;import com.snaplogic.jsonpath.JsonPathImpl;
<i class="no-highlight">32</i>&nbsp;import com.snaplogic.snap.api.Document;
<i class="no-highlight">33</i>&nbsp;import com.snaplogic.snap.api.DocumentUtility;
<i class="no-highlight">34</i>&nbsp;import com.snaplogic.snap.api.ErrorViews;
<i class="no-highlight">35</i>&nbsp;import com.snaplogic.snap.api.ExpressionProperty;
<i class="no-highlight">36</i>&nbsp;import com.snaplogic.snap.api.OutputViews;
<i class="no-highlight">37</i>&nbsp;import com.snaplogic.snap.api.PropertyValues;
<i class="no-highlight">38</i>&nbsp;import com.snaplogic.snap.api.SnapCategory;
<i class="no-highlight">39</i>&nbsp;import com.snaplogic.snap.api.SnapDataException;
<i class="no-highlight">40</i>&nbsp;import com.snaplogic.snap.api.SuggestViewAbortException;
<i class="no-highlight">41</i>&nbsp;import com.snaplogic.snap.api.authentication.KerberosAuthentication;
<i class="no-highlight">42</i>&nbsp;import com.snaplogic.snap.api.binary.AbfsAccount;
<i class="no-highlight">43</i>&nbsp;import com.snaplogic.snap.api.binary.BinaryDefaultAccount;
<i class="no-highlight">44</i>&nbsp;import com.snaplogic.snap.api.binary.BinaryUtils;
<i class="no-highlight">45</i>&nbsp;import com.snaplogic.snap.api.binary.ParquetMapReadSupport;
<i class="no-highlight">46</i>&nbsp;import com.snaplogic.snap.api.binary.ParquetReadSupport;
<i class="no-highlight">47</i>&nbsp;import com.snaplogic.snap.api.binary.ParquetRecord;
<i class="no-highlight">48</i>&nbsp;import com.snaplogic.snap.api.capabilities.Category;
<i class="no-highlight">49</i>&nbsp;import com.snaplogic.snap.api.capabilities.Errors;
<i class="no-highlight">50</i>&nbsp;import com.snaplogic.snap.api.capabilities.General;
<i class="no-highlight">51</i>&nbsp;import com.snaplogic.snap.api.capabilities.Outputs;
<i class="no-highlight">52</i>&nbsp;import com.snaplogic.snap.api.capabilities.Version;
<i class="no-highlight">53</i>&nbsp;import com.snaplogic.snap.api.capabilities.ViewType;
<i class="no-highlight">54</i>&nbsp;import com.snaplogic.snaps.hadoop.common.HdfsUtils;
<i class="no-highlight">55</i>&nbsp;import com.snaplogic.snaps.hadoop.sastoken.SasTokenUtils;
<i class="no-highlight">56</i>&nbsp;import com.snaplogic.snaps.hadoop.util.HadoopConfigUtils;
<i class="no-highlight">57</i>&nbsp;import com.snaplogic.snaps.hadoop.util.S3ErrorHandler;
<i class="no-highlight">58</i>&nbsp;import com.snaplogic.snaps.hadoop.util.WasbErrorHandler;
<i class="no-highlight">59</i>&nbsp;
<i class="no-highlight">60</i>&nbsp;import org.apache.commons.collections.MapUtils;
<i class="no-highlight">61</i>&nbsp;import org.apache.commons.io.IOUtils;
<i class="no-highlight">62</i>&nbsp;import org.apache.commons.lang3.StringUtils;
<i class="no-highlight">63</i>&nbsp;import org.apache.hadoop.conf.Configuration;
<i class="no-highlight">64</i>&nbsp;import org.apache.hadoop.fs.Path;
<i class="no-highlight">65</i>&nbsp;import org.apache.hadoop.fs.azure.AzureException;
<i class="no-highlight">66</i>&nbsp;import org.apache.parquet.HadoopReadOptions;
<i class="no-highlight">67</i>&nbsp;import org.apache.parquet.hadoop.ParquetFileReader;
<i class="no-highlight">68</i>&nbsp;import org.apache.parquet.hadoop.ParquetReader;
<i class="no-highlight">69</i>&nbsp;import org.apache.parquet.hadoop.util.HadoopInputFile;
<i class="no-highlight">70</i>&nbsp;import org.apache.parquet.hadoop.util.HiddenFileFilter;
<i class="no-highlight">71</i>&nbsp;import org.apache.parquet.schema.GroupType;
<i class="no-highlight">72</i>&nbsp;import org.apache.parquet.schema.MessageType;
<i class="no-highlight">73</i>&nbsp;import org.apache.parquet.schema.PrimitiveType;
<i class="no-highlight">74</i>&nbsp;import org.apache.parquet.schema.Type;
<i class="no-highlight">75</i>&nbsp;import org.slf4j.LoggerFactory;
<i class="no-highlight">76</i>&nbsp;
<i class="no-highlight">77</i>&nbsp;import java.io.IOException;
<i class="no-highlight">78</i>&nbsp;import java.math.BigInteger;
<i class="no-highlight">79</i>&nbsp;import java.net.URI;
<i class="no-highlight">80</i>&nbsp;import java.security.PrivilegedAction;
<i class="no-highlight">81</i>&nbsp;import java.security.PrivilegedExceptionAction;
<i class="no-highlight">82</i>&nbsp;import java.time.OffsetDateTime;
<i class="no-highlight">83</i>&nbsp;import java.time.ZoneOffset;
<i class="no-highlight">84</i>&nbsp;import java.time.format.DateTimeFormatter;
<i class="no-highlight">85</i>&nbsp;import java.time.temporal.JulianFields;
<i class="no-highlight">86</i>&nbsp;import java.util.ArrayList;
<i class="no-highlight">87</i>&nbsp;import java.util.Collections;
<i class="no-highlight">88</i>&nbsp;import java.util.List;
<i class="no-highlight">89</i>&nbsp;import java.util.Map;
<i class="no-highlight">90</i>&nbsp;
<i class="no-highlight">91</i>&nbsp;import static com.snaplogic.snap.api.binary.BinaryUtils.DIRECTORY_PROP;
<i class="no-highlight">92</i>&nbsp;import static com.snaplogic.snap.api.binary.BinaryUtils.FILE_PROP;
<i class="no-highlight">93</i>&nbsp;import static com.snaplogic.snap.api.fs.hadoop.Constants.DEFAULT_DIRECTORY;
<i class="no-highlight">94</i>&nbsp;import static com.snaplogic.snap.api.fs.hadoop.Constants.S3A_SCHEME;
<i class="no-highlight">95</i>&nbsp;import static com.snaplogic.snap.api.fs.hadoop.Constants.S3_SCHEME;
<i class="no-highlight">96</i>&nbsp;import static com.snaplogic.snaps.hadoop.Constants.DOLLAR;
<i class="no-highlight">97</i>&nbsp;import static com.snaplogic.snaps.hadoop.Constants.FORMAT_DOT;
<i class="no-highlight">98</i>&nbsp;import static com.snaplogic.snaps.hadoop.Messages.*;
<i class="no-highlight">99</i>&nbsp;import static com.snaplogic.snaps.hadoop.common.HdfsUtils.configToMap;
<i class="no-highlight">100</i>&nbsp;import static com.snaplogic.snaps.hadoop.sastoken.SasTokenUtils.NewHadoopPathAndConfig;
<i class="no-highlight">101</i>&nbsp;
<i class="no-highlight">102</i>&nbsp;/**
<i class="no-highlight">103</i>&nbsp; * ParquetReadingParser snap converts parquet columnar data into SnapLogic documents.
<i class="no-highlight">104</i>&nbsp; */
<i class="no-highlight">105</i>&nbsp;@Version(snap = 1)
<i class="no-highlight">106</i>&nbsp;@General(title = Messages.PARQUET_PARSER_LABEL, purpose = Messages.PARQUET_PARSER_DESC)
<i class="no-highlight">107</i>&nbsp;@Outputs(min = 1, max = 1, offers = {ViewType.DOCUMENT})
<i class="no-highlight">108</i>&nbsp;@Errors(min = 1, max = 1, offers = {ViewType.DOCUMENT})
<i class="no-highlight">109</i>&nbsp;@Category(snap = SnapCategory.READ)
<i class="no-highlight">110</i>&nbsp;@Accounts(provides = {HadoopS3Account.class, HadoopS3DynamicAccount.class, KerberosAccount.class, BinaryAzureAccount.class,
<i class="no-highlight">111</i>&nbsp;        AzureDataLakeAccount.class, AbfsAccount.class}, optional = true)
<b class="nc"><i class="no-highlight">112</i>&nbsp;public class ParquetReadingParser extends AbstractHdfsReader</b>
<i class="no-highlight">113</i>&nbsp;        implements MultiAccountBinding&lt;Account&lt;String&gt;&gt; {
<b class="nc"><i class="no-highlight">114</i>&nbsp;    private static final org.slf4j.Logger LOG = LoggerFactory.getLogger(ParquetReadingParser.class);</b>
<i class="no-highlight">115</i>&nbsp;    private static final String DEBUG_EXEC_PRIV_KERB_FS_ACTION = &quot;Executing &quot; +
<i class="no-highlight">116</i>&nbsp;            &quot;PrivilegedKerberizedFSAction&quot;;
<b class="nc"><i class="no-highlight">117</i>&nbsp;    private static final boolean USER_IMPERSONATION_DEFAULT = Boolean.FALSE;</b>
<i class="no-highlight">118</i>&nbsp;    private static final String IGNORE_EMPTY_FILE_PROP = &quot;ignoreEmptyFile&quot;;
<i class="no-highlight">119</i>&nbsp;    private static final String USE_OLD_DATA_FORMAT_PROP = &quot;useOldDataFormat&quot;;
<i class="no-highlight">120</i>&nbsp;    private static final String ENABLE_IF_NEW_DATA_FORMAT = &quot;!$.settings.useOldDataFormat.value&quot;;
<i class="no-highlight">121</i>&nbsp;    private static final String INT96_AS_TIMESTAMP_PROP = &quot;int96AsTimestamp&quot;;
<i class="no-highlight">122</i>&nbsp;    private static final String USE_DATETIME_TYPES_PROP = &quot;useDateTimeTypes&quot;;
<i class="no-highlight">123</i>&nbsp;    private static final String ENABLE_IF_INT96 = &quot;$.settings.int96AsTimestamp.value&quot;;
<i class="no-highlight">124</i>&nbsp;    private static final String DATE_TIME_FORMAT_PROP = &quot;dateTimeFormat&quot;;
<i class="no-highlight">125</i>&nbsp;    private static final String DEFAULT_DATE_TIME_FORMAT = &quot;yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSSX&quot;;
<i class="no-highlight">126</i>&nbsp;    private static final String INT96 = &quot;int96&quot;;
<i class="no-highlight">127</i>&nbsp;    private static final int MAX_INT96_BYTES = 12;
<i class="no-highlight">128</i>&nbsp;    private boolean ignoreEmptyFile;
<b class="nc"><i class="no-highlight">129</i>&nbsp;    private boolean useOldDataFormat = true;</b>
<b class="nc"><i class="no-highlight">130</i>&nbsp;    private boolean int96AsTimestamp = true;</b>
<i class="no-highlight">131</i>&nbsp;    private ExpressionProperty dateTimeFormatExpr;
<i class="no-highlight">132</i>&nbsp;    @Inject
<i class="no-highlight">133</i>&nbsp;    private BinaryUtils binaryUtils;
<i class="no-highlight">134</i>&nbsp;    @Inject
<i class="no-highlight">135</i>&nbsp;    private Account&lt;String&gt; account;
<i class="no-highlight">136</i>&nbsp;    private boolean useDateTimeTypes;
<i class="no-highlight">137</i>&nbsp;
<i class="no-highlight">138</i>&nbsp;    @Override
<i class="no-highlight">139</i>&nbsp;    public Module getManagedAccountModule(final Account&lt;String&gt; account) {
<b class="nc"><i class="no-highlight">140</i>&nbsp;        return new AbstractModule() {</b>
<i class="no-highlight">141</i>&nbsp;            @Override
<i class="no-highlight">142</i>&nbsp;            protected void configure() {
<b class="nc"><i class="no-highlight">143</i>&nbsp;                if (account == null) {</b>
<b class="nc"><i class="no-highlight">144</i>&nbsp;                    bind(Key.get(new TypeLiteral&lt;Account&lt;String&gt;&gt;() {</b>
<i class="no-highlight">145</i>&nbsp;                    }))
<b class="nc"><i class="no-highlight">146</i>&nbsp;                            .to(BinaryDefaultAccount.class)</b>
<b class="nc"><i class="no-highlight">147</i>&nbsp;                            .in(Scopes.SINGLETON);</b>
<i class="no-highlight">148</i>&nbsp;                } else {
<b class="nc"><i class="no-highlight">149</i>&nbsp;                    bind(Key.get(new TypeLiteral&lt;Account&lt;String&gt;&gt;() {</b>
<b class="nc"><i class="no-highlight">150</i>&nbsp;                    })).toInstance(account);</b>
<i class="no-highlight">151</i>&nbsp;                }
<i class="no-highlight">152</i>&nbsp;            }
<i class="no-highlight">153</i>&nbsp;        };
<i class="no-highlight">154</i>&nbsp;    }
<i class="no-highlight">155</i>&nbsp;
<i class="no-highlight">156</i>&nbsp;    @Override
<i class="no-highlight">157</i>&nbsp;    public void defineProperties(PropertyBuilder propertyBuilder) {
<b class="nc"><i class="no-highlight">158</i>&nbsp;        if (account instanceof HadoopS3Account || account instanceof HadoopS3DynamicAccount) {</b>
<b class="nc"><i class="no-highlight">159</i>&nbsp;            binaryUtils.defineFileProperties(propertyBuilder, DEFAULT_DIRECTORY, account, false, abfsRestUtility);</b>
<i class="no-highlight">160</i>&nbsp;        } else {
<b class="nc"><i class="no-highlight">161</i>&nbsp;            binaryUtils.definePropertiesWithSuggestions(propertyBuilder, DEFAULT_DIRECTORY, false,</b>
<i class="no-highlight">162</i>&nbsp;                    new BinaryUtils.HdfsFileSuggester(DIRECTORY_PROP, new ReadHdfsSupplier(),
<i class="no-highlight">163</i>&nbsp;                            abfsRestUtility),
<i class="no-highlight">164</i>&nbsp;                    new BinaryUtils.HdfsFileSuggester(FILE_PROP, new ReadHdfsSupplier(),
<i class="no-highlight">165</i>&nbsp;                            abfsRestUtility));
<b class="nc"><i class="no-highlight">166</i>&nbsp;            propertyBuilder.describe(HdfsUtils.USER_IMPERSONATION_ENABLED, USER_IMPERSONATION_TITLE,</b>
<i class="no-highlight">167</i>&nbsp;                    USER_IMPERSONATION_DESC)
<b class="nc"><i class="no-highlight">168</i>&nbsp;                    .type(SnapType.BOOLEAN)</b>
<b class="nc"><i class="no-highlight">169</i>&nbsp;                    .defaultValue(USER_IMPERSONATION_DEFAULT)</b>
<b class="nc"><i class="no-highlight">170</i>&nbsp;                    .add();</b>
<i class="no-highlight">171</i>&nbsp;        }
<b class="nc"><i class="no-highlight">172</i>&nbsp;        propertyBuilder.describe(IGNORE_EMPTY_FILE_PROP, IGNORE_EMPTY_FILE_LABEL,</b>
<i class="no-highlight">173</i>&nbsp;                IGNORE_EMPTY_FILE_DESC)
<b class="nc"><i class="no-highlight">174</i>&nbsp;                .type(SnapType.BOOLEAN)</b>
<b class="nc"><i class="no-highlight">175</i>&nbsp;                .defaultValue(Boolean.TRUE)</b>
<b class="nc"><i class="no-highlight">176</i>&nbsp;                .add();</b>
<b class="nc"><i class="no-highlight">177</i>&nbsp;        propertyBuilder.describe(USE_OLD_DATA_FORMAT_PROP, USE_OLD_DATA_FORMAT_LABEL,</b>
<i class="no-highlight">178</i>&nbsp;                USE_OLD_DATA_FORMAT_DESC)
<b class="nc"><i class="no-highlight">179</i>&nbsp;                .type(SnapType.BOOLEAN)</b>
<b class="nc"><i class="no-highlight">180</i>&nbsp;                .defaultValue(Boolean.TRUE)</b>
<b class="nc"><i class="no-highlight">181</i>&nbsp;                .add();</b>
<b class="nc"><i class="no-highlight">182</i>&nbsp;        propertyBuilder.describe(INT96_AS_TIMESTAMP_PROP, INT96_AS_TIMESTAMP_LABEL,</b>
<i class="no-highlight">183</i>&nbsp;                INT96_AS_TIMESTAMP_DESC)
<b class="nc"><i class="no-highlight">184</i>&nbsp;                .type(SnapType.BOOLEAN)</b>
<b class="nc"><i class="no-highlight">185</i>&nbsp;                .enableIf(ENABLE_IF_NEW_DATA_FORMAT)</b>
<b class="nc"><i class="no-highlight">186</i>&nbsp;                .add();</b>
<b class="nc"><i class="no-highlight">187</i>&nbsp;        propertyBuilder.describe(USE_DATETIME_TYPES_PROP, USE_DATETIME_TYPES_LABEL,</b>
<i class="no-highlight">188</i>&nbsp;                        USE_DATETIME_TYPES__DESC)
<b class="nc"><i class="no-highlight">189</i>&nbsp;                .type(SnapType.BOOLEAN)</b>
<b class="nc"><i class="no-highlight">190</i>&nbsp;                .defaultValue(false)</b>
<b class="nc"><i class="no-highlight">191</i>&nbsp;                .add();</b>
<b class="nc"><i class="no-highlight">192</i>&nbsp;        propertyBuilder.describe(DATE_TIME_FORMAT_PROP, DATE_TIME_FORMAT_LABEL,</b>
<i class="no-highlight">193</i>&nbsp;                DATE_TIME_FORMAT_DESC)
<b class="nc"><i class="no-highlight">194</i>&nbsp;                .enableIf(ENABLE_IF_INT96)</b>
<b class="nc"><i class="no-highlight">195</i>&nbsp;                .expression(SnapProperty.DecoratorType.ACCEPTS_SCHEMA)</b>
<b class="nc"><i class="no-highlight">196</i>&nbsp;                .defaultValue(DEFAULT_DATE_TIME_FORMAT)</b>
<b class="nc"><i class="no-highlight">197</i>&nbsp;                .add();</b>
<b class="nc"><i class="no-highlight">198</i>&nbsp;        if (supportAzureSasUri()) {</b>
<b class="nc"><i class="no-highlight">199</i>&nbsp;            super.addSasUriProperties(propertyBuilder);</b>
<i class="no-highlight">200</i>&nbsp;        }
<i class="no-highlight">201</i>&nbsp;    }
<i class="no-highlight">202</i>&nbsp;
<i class="no-highlight">203</i>&nbsp;    @Override
<i class="no-highlight">204</i>&nbsp;    protected boolean supportAzureSasUri() {
<b class="nc"><i class="no-highlight">205</i>&nbsp;        return true;</b>
<i class="no-highlight">206</i>&nbsp;    }
<i class="no-highlight">207</i>&nbsp;
<i class="no-highlight">208</i>&nbsp;    @Override
<i class="no-highlight">209</i>&nbsp;    public void configure(final PropertyValues propertyValues) throws ConfigurationException {
<b class="nc"><i class="no-highlight">210</i>&nbsp;        super.configure(propertyValues);</b>
<b class="nc"><i class="no-highlight">211</i>&nbsp;        initializeTempDir(propertyValues);</b>
<b class="nc"><i class="no-highlight">212</i>&nbsp;        Boolean value = propertyValues.get(IGNORE_EMPTY_FILE_PROP);</b>
<b class="nc"><i class="no-highlight">213</i>&nbsp;        ignoreEmptyFile = value == null ? true : value;</b>
<b class="nc"><i class="no-highlight">214</i>&nbsp;        value = propertyValues.get(USE_OLD_DATA_FORMAT_PROP);</b>
<b class="nc"><i class="no-highlight">215</i>&nbsp;        useOldDataFormat = value == null ? true : value;</b>
<b class="nc"><i class="no-highlight">216</i>&nbsp;        handleSasUri(propertyValues);</b>
<b class="nc"><i class="no-highlight">217</i>&nbsp;        int96AsTimestamp = propertyValues.getBoolean(INT96_AS_TIMESTAMP_PROP, false);</b>
<b class="nc"><i class="no-highlight">218</i>&nbsp;        useDateTimeTypes = propertyValues.getBoolean(USE_DATETIME_TYPES_PROP, false);</b>
<b class="nc"><i class="no-highlight">219</i>&nbsp;        dateTimeFormatExpr = propertyValues.getAsExpression(DATE_TIME_FORMAT_PROP);</b>
<i class="no-highlight">220</i>&nbsp;    }
<i class="no-highlight">221</i>&nbsp;
<i class="no-highlight">222</i>&nbsp;    @Override
<i class="no-highlight">223</i>&nbsp;    protected void doRead(Document document, final String filename, URI pathUri) {
<i class="no-highlight">224</i>&nbsp;        try {
<b class="nc"><i class="no-highlight">225</i>&nbsp;            user.doAs((PrivilegedAction&lt;Void&gt;) () -&gt; {</b>
<b class="nc"><i class="no-highlight">226</i>&nbsp;                doReadImpl(document, filename, pathUri);</b>
<b class="nc"><i class="no-highlight">227</i>&nbsp;                if (document != null) {</b>
<b class="nc"><i class="no-highlight">228</i>&nbsp;                    document.acknowledge();</b>
<i class="no-highlight">229</i>&nbsp;                }
<b class="nc"><i class="no-highlight">230</i>&nbsp;                return null;</b>
<i class="no-highlight">231</i>&nbsp;            });
<b class="nc"><i class="no-highlight">232</i>&nbsp;        } catch (SnapDataException e) {</b>
<b class="nc"><i class="no-highlight">233</i>&nbsp;            errorViews.write(e, document);</b>
<b class="nc"><i class="no-highlight">234</i>&nbsp;        } catch (SuggestViewAbortException e) {</b>
<b class="nc"><i class="no-highlight">235</i>&nbsp;            throw e;</b>
<b class="nc"><i class="no-highlight">236</i>&nbsp;        } catch (Exception e) {</b>
<b class="nc"><i class="no-highlight">237</i>&nbsp;            errorViews.write((SnapDataException) new SnapDataException(e, ERR_PARQUET_READER)</b>
<b class="nc"><i class="no-highlight">238</i>&nbsp;                    .formatWith(pathUri.getPath())</b>
<b class="nc"><i class="no-highlight">239</i>&nbsp;                    .withResolution(RESOLUTION_ADDRESS_ISSUE), document);</b>
<b class="nc"><i class="no-highlight">240</i>&nbsp;        }</b>
<i class="no-highlight">241</i>&nbsp;    }
<i class="no-highlight">242</i>&nbsp;
<i class="no-highlight">243</i>&nbsp;    @VisibleForTesting
<i class="no-highlight">244</i>&nbsp;    protected void doReadImpl(Document document, final String filename, URI pathUri) {
<b class="nc"><i class="no-highlight">245</i>&nbsp;        String dateTimeFormat = dateTimeFormatExpr.eval(document);</b>
<b class="nc"><i class="no-highlight">246</i>&nbsp;        pathUri = getUriTempFile(document, filename, pathUri);</b>
<b class="nc"><i class="no-highlight">247</i>&nbsp;        Path path = new Path(pathUri);</b>
<b class="nc"><i class="no-highlight">248</i>&nbsp;        final Map&lt;String, Object&gt; header = createHeader(pathUri, Collections.emptyMap());</b>
<b class="nc"><i class="no-highlight">249</i>&nbsp;        final Document headerDocument = documentUtility.newDocumentFor(document, header);</b>
<b class="nc"><i class="no-highlight">250</i>&nbsp;        Object reader = null;</b>
<b class="nc"><i class="no-highlight">251</i>&nbsp;        Configuration hadoopConfig = configurationSupplier.get();</b>
<b class="nc"><i class="no-highlight">252</i>&nbsp;        HadoopConfigUtils.adjustConfig(hadoopConfig, account);</b>
<b class="nc"><i class="no-highlight">253</i>&nbsp;        LOG.debug(HADOOP_CONFIG_LOG, configToMap(hadoopConfig));</b>
<b class="nc"><i class="no-highlight">254</i>&nbsp;        if (azureSasUriProperties != null) {</b>
<b class="nc"><i class="no-highlight">255</i>&nbsp;            extractSasToken(document);</b>
<i class="no-highlight">256</i>&nbsp;        }
<b class="nc"><i class="no-highlight">257</i>&nbsp;        NewHadoopPathAndConfig newHadoopPathAndConfig = SasTokenUtils</b>
<b class="nc"><i class="no-highlight">258</i>&nbsp;                .addSasTokenIfRequiredAndGetNewPathAndConfig(hadoopConfig, filename,</b>
<i class="no-highlight">259</i>&nbsp;                        sasTokenFromSnap, sasTokenFromAccount, account, authTypeSasUri,
<i class="no-highlight">260</i>&nbsp;                        accountName);
<b class="nc"><i class="no-highlight">261</i>&nbsp;        if (newHadoopPathAndConfig != null) {</b>
<b class="nc"><i class="no-highlight">262</i>&nbsp;            path = newHadoopPathAndConfig.getPath();</b>
<b class="nc"><i class="no-highlight">263</i>&nbsp;            hadoopConfig = newHadoopPathAndConfig.getConfiguration();</b>
<i class="no-highlight">264</i>&nbsp;        }
<i class="no-highlight">265</i>&nbsp;
<b class="nc"><i class="no-highlight">266</i>&nbsp;        if (!HiddenFileFilter.INSTANCE.accept(path)) {</b>
<i class="no-highlight">267</i>&nbsp;            // ignore &quot;hidden&quot; files such as _SUCCESS
<b class="nc"><i class="no-highlight">268</i>&nbsp;            LOG.debug(&quot;skipping hidden file: {}&quot;, path);</b>
<i class="no-highlight">269</i>&nbsp;            return;
<i class="no-highlight">270</i>&nbsp;        }
<i class="no-highlight">271</i>&nbsp;
<b class="nc"><i class="no-highlight">272</i>&nbsp;        if (account instanceof KerberosAccount &amp;&amp; isAuthenticatedWithKerberos()) {</b>
<i class="no-highlight">273</i>&nbsp;            try {
<b class="nc"><i class="no-highlight">274</i>&nbsp;                HdfsUtils.updateConfWithKerberosAuthentication(hadoopConfig);</b>
<b class="nc"><i class="no-highlight">275</i>&nbsp;                final Path finalPath = path;</b>
<b class="nc"><i class="no-highlight">276</i>&nbsp;                KerberosAuthentication.runHadoopPrivilegedAction(</b>
<i class="no-highlight">277</i>&nbsp;                        new PrivilegedKerberizedParquetReader(document, hadoopConfig, finalPath,
<i class="no-highlight">278</i>&nbsp;                        headerDocument, outputViews, errorViews, documentUtility, ignoreEmptyFile,
<i class="no-highlight">279</i>&nbsp;                        useOldDataFormat, int96AsTimestamp, dateTimeFormat, useDateTimeTypes),
<i class="no-highlight">280</i>&nbsp;                        this.kerberosConfig);
<b class="nc"><i class="no-highlight">281</i>&nbsp;            } catch (IOException e) {</b>
<b class="nc"><i class="no-highlight">282</i>&nbsp;                String reason = String.format(FAILED_TO_READ_KERBEROS_INCOMING_DATA, e.getMessage</b>
<b class="nc"><i class="no-highlight">283</i>&nbsp;                        ());</b>
<b class="nc"><i class="no-highlight">284</i>&nbsp;                SnapDataException ex = new SnapDataException(e, UNABLE_TO_READ_INPUT_STREAM)</b>
<b class="nc"><i class="no-highlight">285</i>&nbsp;                        .withReason(reason)</b>
<b class="nc"><i class="no-highlight">286</i>&nbsp;                        .withResolution(ERR_RESOLUTION_INVALIDINPUT);</b>
<b class="nc"><i class="no-highlight">287</i>&nbsp;                errorViews.write(ex, document);</b>
<b class="nc"><i class="no-highlight">288</i>&nbsp;            }</b>
<i class="no-highlight">289</i>&nbsp;        } else {
<i class="no-highlight">290</i>&nbsp;            try {
<b class="nc"><i class="no-highlight">291</i>&nbsp;                reader = readAndParseParquet(document, headerDocument, hadoopConfig, path,</b>
<i class="no-highlight">292</i>&nbsp;                        documentUtility, outputViews, ignoreEmptyFile, useOldDataFormat,
<i class="no-highlight">293</i>&nbsp;                        int96AsTimestamp, dateTimeFormat, useDateTimeTypes);
<b class="nc"><i class="no-highlight">294</i>&nbsp;            } catch (AmazonClientException e) {</b>
<b class="nc"><i class="no-highlight">295</i>&nbsp;                S3ErrorHandler.invalidEndPoint(((HadoopS3Account) account).endpointName, e);</b>
<b class="nc"><i class="no-highlight">296</i>&nbsp;            } catch (AzureException e) {</b>
<b class="nc"><i class="no-highlight">297</i>&nbsp;                WasbErrorHandler.raiseRequestError(e, FAILED_TO_READ_WASB);</b>
<b class="nc"><i class="no-highlight">298</i>&nbsp;            } catch (SnapDataException e) {</b>
<b class="nc"><i class="no-highlight">299</i>&nbsp;                errorViews.write(e, document);</b>
<b class="nc"><i class="no-highlight">300</i>&nbsp;            } catch (IOException e) {</b>
<i class="no-highlight">301</i>&nbsp;                // Converts the &quot;s3a://&quot; inside the message back to &quot;s3://&quot;IO
<b class="nc"><i class="no-highlight">302</i>&nbsp;                String message = e.getMessage().replaceFirst(S3A_SCHEME, S3_SCHEME);</b>
<b class="nc"><i class="no-highlight">303</i>&nbsp;                String reason = String.format(FAILED_TO_READ_INCOMING_DATA, message);</b>
<b class="nc"><i class="no-highlight">304</i>&nbsp;                SnapDataException ex = new SnapDataException(e, UNABLE_TO_READ_INPUT_STREAM)</b>
<b class="nc"><i class="no-highlight">305</i>&nbsp;                        .withReason(reason)</b>
<b class="nc"><i class="no-highlight">306</i>&nbsp;                        .withResolution(ERR_RESOLUTION_INVALIDINPUT);</b>
<b class="nc"><i class="no-highlight">307</i>&nbsp;                errorViews.write(ex, document);</b>
<i class="no-highlight">308</i>&nbsp;            } finally {
<b class="nc"><i class="no-highlight">309</i>&nbsp;                if (reader instanceof ParquetReader) {</b>
<b class="nc"><i class="no-highlight">310</i>&nbsp;                    IOUtils.closeQuietly((ParquetReader) reader);</b>
<i class="no-highlight">311</i>&nbsp;                }
<b class="nc"><i class="no-highlight">312</i>&nbsp;                cleanupTempFile(DELETE_TEMP_FILE_MESSAGE_PARQUET);</b>
<b class="nc"><i class="no-highlight">313</i>&nbsp;            }</b>
<i class="no-highlight">314</i>&nbsp;        }
<i class="no-highlight">315</i>&nbsp;    }
<i class="no-highlight">316</i>&nbsp;
<i class="no-highlight">317</i>&nbsp;    @Override
<i class="no-highlight">318</i>&nbsp;    public void cleanup() throws ExecutionException {
<i class="no-highlight">319</i>&nbsp;        //no-op
<i class="no-highlight">320</i>&nbsp;    }
<i class="no-highlight">321</i>&nbsp;
<i class="no-highlight">322</i>&nbsp;    /**
<i class="no-highlight">323</i>&nbsp;     * Executes the getConnection() for the given Datasource object using Kerberos as a privileged
<i class="no-highlight">324</i>&nbsp;     * action. This action reads parquet file and parses it.
<i class="no-highlight">325</i>&nbsp;     */
<i class="no-highlight">326</i>&nbsp;    private static class PrivilegedKerberizedParquetReader implements
<i class="no-highlight">327</i>&nbsp;            PrivilegedExceptionAction&lt;Void&gt; {
<i class="no-highlight">328</i>&nbsp;        final Configuration hadoopConfig;
<i class="no-highlight">329</i>&nbsp;        Document headerDocument;
<i class="no-highlight">330</i>&nbsp;        Document original;
<i class="no-highlight">331</i>&nbsp;        Path path;
<i class="no-highlight">332</i>&nbsp;        OutputViews outputViews;
<i class="no-highlight">333</i>&nbsp;        ErrorViews errorViews;
<i class="no-highlight">334</i>&nbsp;        DocumentUtility documentUtility;
<i class="no-highlight">335</i>&nbsp;        private boolean ignoreEmptyFile;
<i class="no-highlight">336</i>&nbsp;        private boolean useOldDataFormat;
<i class="no-highlight">337</i>&nbsp;        private boolean int96AsTimestamp;
<i class="no-highlight">338</i>&nbsp;        private String dateTimeFormat;
<i class="no-highlight">339</i>&nbsp;        private boolean useDateTimeTypes;
<i class="no-highlight">340</i>&nbsp;
<i class="no-highlight">341</i>&nbsp;        public PrivilegedKerberizedParquetReader(final Document original, Configuration
<i class="no-highlight">342</i>&nbsp;                configuration, Path path, Document headerDocument, OutputViews outputViews,
<i class="no-highlight">343</i>&nbsp;                ErrorViews errorViews, DocumentUtility documentUtility, boolean ignoreEmptyFile,
<i class="no-highlight">344</i>&nbsp;                boolean useOldDataFormat, boolean int96AsTimestamp, String dateTimeFormat,
<b class="nc"><i class="no-highlight">345</i>&nbsp;                boolean useDateTimeTypes) {</b>
<b class="nc"><i class="no-highlight">346</i>&nbsp;            this.hadoopConfig = configuration;</b>
<b class="nc"><i class="no-highlight">347</i>&nbsp;            this.headerDocument = headerDocument;</b>
<b class="nc"><i class="no-highlight">348</i>&nbsp;            this.original = original;</b>
<b class="nc"><i class="no-highlight">349</i>&nbsp;            this.path = path;</b>
<b class="nc"><i class="no-highlight">350</i>&nbsp;            this.documentUtility = documentUtility;</b>
<b class="nc"><i class="no-highlight">351</i>&nbsp;            this.outputViews = outputViews;</b>
<b class="nc"><i class="no-highlight">352</i>&nbsp;            this.errorViews = errorViews;</b>
<b class="nc"><i class="no-highlight">353</i>&nbsp;            this.ignoreEmptyFile = ignoreEmptyFile;</b>
<b class="nc"><i class="no-highlight">354</i>&nbsp;            this.useOldDataFormat = useOldDataFormat;</b>
<b class="nc"><i class="no-highlight">355</i>&nbsp;            this.int96AsTimestamp = int96AsTimestamp;</b>
<b class="nc"><i class="no-highlight">356</i>&nbsp;            this.dateTimeFormat = dateTimeFormat;</b>
<b class="nc"><i class="no-highlight">357</i>&nbsp;            this.useDateTimeTypes = useDateTimeTypes;</b>
<i class="no-highlight">358</i>&nbsp;        }
<i class="no-highlight">359</i>&nbsp;
<i class="no-highlight">360</i>&nbsp;        public Void run() throws IOException {
<b class="nc"><i class="no-highlight">361</i>&nbsp;            LOG.debug(DEBUG_EXEC_PRIV_KERB_FS_ACTION);</b>
<b class="nc"><i class="no-highlight">362</i>&nbsp;            readParquet(original, headerDocument, hadoopConfig, path, documentUtility, outputViews);</b>
<b class="nc"><i class="no-highlight">363</i>&nbsp;            return null;</b>
<i class="no-highlight">364</i>&nbsp;        }
<i class="no-highlight">365</i>&nbsp;
<i class="no-highlight">366</i>&nbsp;        private void readParquet(final Document original, Document headerDocument,
<i class="no-highlight">367</i>&nbsp;                Configuration hadoopConfig, Path path, DocumentUtility documentUtility,
<i class="no-highlight">368</i>&nbsp;                OutputViews outputViews) throws IOException {
<b class="nc"><i class="no-highlight">369</i>&nbsp;            Object reader = null;</b>
<i class="no-highlight">370</i>&nbsp;            try {
<b class="nc"><i class="no-highlight">371</i>&nbsp;                reader = readAndParseParquet(original, headerDocument, hadoopConfig, path,</b>
<i class="no-highlight">372</i>&nbsp;                        documentUtility, outputViews, ignoreEmptyFile, useOldDataFormat,
<i class="no-highlight">373</i>&nbsp;                        int96AsTimestamp, dateTimeFormat, useDateTimeTypes);
<b class="nc"><i class="no-highlight">374</i>&nbsp;            } catch (SnapDataException e) {</b>
<b class="nc"><i class="no-highlight">375</i>&nbsp;                errorViews.write(e, original);</b>
<i class="no-highlight">376</i>&nbsp;            } finally {
<b class="nc"><i class="no-highlight">377</i>&nbsp;                if (reader instanceof ParquetReader) {</b>
<b class="nc"><i class="no-highlight">378</i>&nbsp;                    IOUtils.closeQuietly((ParquetReader) reader);</b>
<i class="no-highlight">379</i>&nbsp;                }
<b class="nc"><i class="no-highlight">380</i>&nbsp;            }</b>
<i class="no-highlight">381</i>&nbsp;        }
<i class="no-highlight">382</i>&nbsp;    }
<i class="no-highlight">383</i>&nbsp;
<i class="no-highlight">384</i>&nbsp;    private static Object readAndParseParquet(final Document original, Document headerDocument,
<i class="no-highlight">385</i>&nbsp;            Configuration hadoopConfig, Path path, DocumentUtility documentUtility,
<i class="no-highlight">386</i>&nbsp;            OutputViews outputViews, boolean ignoreEmptyFile, boolean useOldDataFormat,
<i class="no-highlight">387</i>&nbsp;            boolean int96AsTimestamp, String dateTimeFormat, boolean useDateTimeTypes) throws IOException {
<b class="nc"><i class="no-highlight">388</i>&nbsp;        if (useOldDataFormat) {</b>
<b class="nc"><i class="no-highlight">389</i>&nbsp;            return readParquetFileWithOldSupport(original, headerDocument, hadoopConfig, path,</b>
<i class="no-highlight">390</i>&nbsp;                    documentUtility, outputViews, ignoreEmptyFile, useDateTimeTypes);
<i class="no-highlight">391</i>&nbsp;        } else {
<b class="nc"><i class="no-highlight">392</i>&nbsp;            return readParquetFileWithNewSupport(original, headerDocument, hadoopConfig, path,</b>
<i class="no-highlight">393</i>&nbsp;                    documentUtility, outputViews, ignoreEmptyFile, int96AsTimestamp,
<i class="no-highlight">394</i>&nbsp;                    dateTimeFormat, useDateTimeTypes);
<i class="no-highlight">395</i>&nbsp;        }
<i class="no-highlight">396</i>&nbsp;    }
<i class="no-highlight">397</i>&nbsp;
<i class="no-highlight">398</i>&nbsp;    private static Object readParquetFileWithNewSupport(final Document original,
<i class="no-highlight">399</i>&nbsp;            final Document headerDocument, final Configuration hadoopConfig, final Path path,
<i class="no-highlight">400</i>&nbsp;            final DocumentUtility documentUtility, final OutputViews outputViews,
<i class="no-highlight">401</i>&nbsp;            final boolean ignoreEmptyFile, final boolean int96AsTimestamp,
<i class="no-highlight">402</i>&nbsp;            final String dateTimeFormat, boolean useDateTimeTypes) throws IOException {
<b class="nc"><i class="no-highlight">403</i>&nbsp;        ParquetReader&lt;ParquetRecord&gt; reader = ParquetReader</b>
<b class="nc"><i class="no-highlight">404</i>&nbsp;                .builder(new ParquetReadSupport(useDateTimeTypes), path)</b>
<b class="nc"><i class="no-highlight">405</i>&nbsp;                .withConf(hadoopConfig)</b>
<b class="nc"><i class="no-highlight">406</i>&nbsp;                .build();</b>
<b class="nc"><i class="no-highlight">407</i>&nbsp;        ParquetRecord value = reader.read();</b>
<i class="no-highlight">408</i>&nbsp;
<b class="nc"><i class="no-highlight">409</i>&nbsp;        if (!ignoreEmptyFile &amp;&amp; value == null) {</b>
<b class="nc"><i class="no-highlight">410</i>&nbsp;            Document documentOut = documentUtility</b>
<b class="nc"><i class="no-highlight">411</i>&nbsp;                    .newDocumentFor(headerDocument, MapUtils.EMPTY_MAP);</b>
<b class="nc"><i class="no-highlight">412</i>&nbsp;            outputViews.write(documentOut, original);</b>
<b class="nc"><i class="no-highlight">413</i>&nbsp;            return reader;</b>
<i class="no-highlight">414</i>&nbsp;        }
<b class="nc"><i class="no-highlight">415</i>&nbsp;        List&lt;String&gt; int96Columns = getInt96Columns(int96AsTimestamp, hadoopConfig, path);</b>
<b class="nc"><i class="no-highlight">416</i>&nbsp;        while (value != null) {</b>
<b class="nc"><i class="no-highlight">417</i>&nbsp;            Map&lt;String, Object&gt; data = (Map&lt;String, Object&gt;) value.convertToJson();</b>
<b class="nc"><i class="no-highlight">418</i>&nbsp;            for (String column : int96Columns) {</b>
<b class="nc"><i class="no-highlight">419</i>&nbsp;                convertInt96ToTimestamp(column, data, dateTimeFormat);</b>
<b class="nc"><i class="no-highlight">420</i>&nbsp;            }</b>
<b class="nc"><i class="no-highlight">421</i>&nbsp;            Document documentOut = documentUtility.newDocumentFor(headerDocument, data);</b>
<b class="nc"><i class="no-highlight">422</i>&nbsp;            outputViews.write(documentOut, original);</b>
<b class="nc"><i class="no-highlight">423</i>&nbsp;            value = reader.read();</b>
<b class="nc"><i class="no-highlight">424</i>&nbsp;        }</b>
<b class="nc"><i class="no-highlight">425</i>&nbsp;        return reader;</b>
<i class="no-highlight">426</i>&nbsp;    }
<i class="no-highlight">427</i>&nbsp;
<i class="no-highlight">428</i>&nbsp;    private static Object readParquetFileWithOldSupport(final Document original,
<i class="no-highlight">429</i>&nbsp;          final Document headerDocument, final Configuration hadoopConfig, final Path path,
<i class="no-highlight">430</i>&nbsp;          final DocumentUtility documentUtility, final OutputViews outputViews,
<i class="no-highlight">431</i>&nbsp;          final boolean ignoreEmptyFile, boolean useDateTimeTypes) throws IOException {
<b class="nc"><i class="no-highlight">432</i>&nbsp;        ParquetReader&lt;Map&lt;String, Object&gt;&gt; reader = ParquetReader</b>
<b class="nc"><i class="no-highlight">433</i>&nbsp;                .builder(new ParquetMapReadSupport(useDateTimeTypes), path)</b>
<b class="nc"><i class="no-highlight">434</i>&nbsp;                .withConf(hadoopConfig)</b>
<b class="nc"><i class="no-highlight">435</i>&nbsp;                .build();</b>
<b class="nc"><i class="no-highlight">436</i>&nbsp;        Map&lt;String, Object&gt; value = reader.read();</b>
<i class="no-highlight">437</i>&nbsp;
<b class="nc"><i class="no-highlight">438</i>&nbsp;        if (!ignoreEmptyFile &amp;&amp; value == null) {</b>
<b class="nc"><i class="no-highlight">439</i>&nbsp;            Document documentOut = documentUtility</b>
<b class="nc"><i class="no-highlight">440</i>&nbsp;                    .newDocumentFor(headerDocument, MapUtils.EMPTY_MAP);</b>
<b class="nc"><i class="no-highlight">441</i>&nbsp;            outputViews.write(documentOut, original);</b>
<b class="nc"><i class="no-highlight">442</i>&nbsp;            return reader;</b>
<i class="no-highlight">443</i>&nbsp;        }
<b class="nc"><i class="no-highlight">444</i>&nbsp;        while (value != null) {</b>
<b class="nc"><i class="no-highlight">445</i>&nbsp;            Document documentOut = documentUtility.newDocumentFor(headerDocument, value);</b>
<b class="nc"><i class="no-highlight">446</i>&nbsp;            outputViews.write(documentOut, original);</b>
<b class="nc"><i class="no-highlight">447</i>&nbsp;            value = reader.read();</b>
<b class="nc"><i class="no-highlight">448</i>&nbsp;        }</b>
<b class="nc"><i class="no-highlight">449</i>&nbsp;        return reader;</b>
<i class="no-highlight">450</i>&nbsp;    }
<i class="no-highlight">451</i>&nbsp;
<i class="no-highlight">452</i>&nbsp;    private static List&lt;String&gt; getInt96Columns(boolean int96AsTimestamp,
<i class="no-highlight">453</i>&nbsp;            Configuration hadoopConfig, Path path) throws IOException {
<b class="nc"><i class="no-highlight">454</i>&nbsp;        List&lt;String&gt; int96Columns = new ArrayList&lt;&gt;();</b>
<b class="nc"><i class="no-highlight">455</i>&nbsp;        if (int96AsTimestamp) {</b>
<b class="nc"><i class="no-highlight">456</i>&nbsp;            ParquetFileReader parquetFileReader =</b>
<b class="nc"><i class="no-highlight">457</i>&nbsp;                    ParquetFileReader.open(HadoopInputFile.fromPath(path, hadoopConfig),</b>
<b class="nc"><i class="no-highlight">458</i>&nbsp;                    HadoopReadOptions.builder(hadoopConfig).build());</b>
<b class="nc"><i class="no-highlight">459</i>&nbsp;            MessageType schema = parquetFileReader.getFileMetaData().getSchema();</b>
<b class="nc"><i class="no-highlight">460</i>&nbsp;            for (Type type : schema.getFields()) {</b>
<b class="nc"><i class="no-highlight">461</i>&nbsp;                if (type instanceof GroupType) {</b>
<b class="nc"><i class="no-highlight">462</i>&nbsp;                    parseGroupType((GroupType) type, DOLLAR.concat(type.getName()), int96Columns);</b>
<b class="nc"><i class="no-highlight">463</i>&nbsp;                } else if (isInt96Type(type)) {</b>
<b class="nc"><i class="no-highlight">464</i>&nbsp;                    int96Columns.add(DOLLAR.concat(type.getName()));</b>
<i class="no-highlight">465</i>&nbsp;                }
<b class="nc"><i class="no-highlight">466</i>&nbsp;            }</b>
<i class="no-highlight">467</i>&nbsp;        }
<b class="nc"><i class="no-highlight">468</i>&nbsp;        return int96Columns;</b>
<i class="no-highlight">469</i>&nbsp;    }
<i class="no-highlight">470</i>&nbsp;
<i class="no-highlight">471</i>&nbsp;    private static void convertInt96ToTimestamp(String path, Map&lt;String, Object&gt; map,
<i class="no-highlight">472</i>&nbsp;            String dateTimeFormat) {
<i class="no-highlight">473</i>&nbsp;        try {
<b class="nc"><i class="no-highlight">474</i>&nbsp;            JsonPath jsonPath = JsonPathImpl.compile(path);</b>
<b class="nc"><i class="no-highlight">475</i>&nbsp;            if (jsonPath.existsIn(map)) {</b>
<b class="nc"><i class="no-highlight">476</i>&nbsp;                Object value = jsonPath.read(map);</b>
<b class="nc"><i class="no-highlight">477</i>&nbsp;                if (value != null) {</b>
<b class="nc"><i class="no-highlight">478</i>&nbsp;                    if (value instanceof BigInteger) {</b>
<b class="nc"><i class="no-highlight">479</i>&nbsp;                        jsonPath.write(map, int96ToTimestamp((BigInteger) value, dateTimeFormat));</b>
<i class="no-highlight">480</i>&nbsp;                    } else {
<b class="nc"><i class="no-highlight">481</i>&nbsp;                        throw new SnapDataException(ERR_INVALID_INT96_VALUE)</b>
<b class="nc"><i class="no-highlight">482</i>&nbsp;                                .formatWith(path)</b>
<b class="nc"><i class="no-highlight">483</i>&nbsp;                                .withReason(String.format(REASON_EXPECTED_BIG_INTEGER,</b>
<b class="nc"><i class="no-highlight">484</i>&nbsp;                                        value.getClass()))</b>
<b class="nc"><i class="no-highlight">485</i>&nbsp;                                .withResolution(RESOLUTION_ADDRESS_ISSUE);</b>
<i class="no-highlight">486</i>&nbsp;                    }
<i class="no-highlight">487</i>&nbsp;                }
<i class="no-highlight">488</i>&nbsp;            }
<b class="nc"><i class="no-highlight">489</i>&nbsp;        } catch (InvalidPathException e) {</b>
<b class="nc"><i class="no-highlight">490</i>&nbsp;            throw new SnapDataException(e, ERR_CONVERT_INT96_TIMESTAMP)</b>
<b class="nc"><i class="no-highlight">491</i>&nbsp;                    .formatWith(path)</b>
<b class="nc"><i class="no-highlight">492</i>&nbsp;                    .withResolution(RESOLUTION_ADDRESS_ISSUE);</b>
<b class="nc"><i class="no-highlight">493</i>&nbsp;        }</b>
<i class="no-highlight">494</i>&nbsp;    }
<i class="no-highlight">495</i>&nbsp;
<i class="no-highlight">496</i>&nbsp;    private static void parseGroupType(GroupType groupType, String jsonPath,
<i class="no-highlight">497</i>&nbsp;            List&lt;String&gt; int96Columns) {
<b class="nc"><i class="no-highlight">498</i>&nbsp;        for (Type type : groupType.getFields()) {</b>
<i class="no-highlight">499</i>&nbsp;            String path;
<b class="nc"><i class="no-highlight">500</i>&nbsp;            if (type instanceof GroupType) {</b>
<b class="nc"><i class="no-highlight">501</i>&nbsp;                path = String.format(FORMAT_DOT, jsonPath, type.getName());</b>
<b class="nc"><i class="no-highlight">502</i>&nbsp;                parseGroupType((GroupType) type, path, int96Columns);</b>
<b class="nc"><i class="no-highlight">503</i>&nbsp;            } else if (isInt96Type(type)) {</b>
<b class="nc"><i class="no-highlight">504</i>&nbsp;                path = String.format(FORMAT_DOT, jsonPath, type.getName());</b>
<b class="nc"><i class="no-highlight">505</i>&nbsp;                int96Columns.add(path);</b>
<i class="no-highlight">506</i>&nbsp;            }
<b class="nc"><i class="no-highlight">507</i>&nbsp;        }</b>
<i class="no-highlight">508</i>&nbsp;    }
<i class="no-highlight">509</i>&nbsp;
<i class="no-highlight">510</i>&nbsp;    private static boolean isInt96Type(Type type) {
<b class="nc"><i class="no-highlight">511</i>&nbsp;        return type instanceof PrimitiveType &amp;&amp;</b>
<b class="nc"><i class="no-highlight">512</i>&nbsp;                INT96.equalsIgnoreCase(((PrimitiveType) type).getPrimitiveTypeName().name());</b>
<i class="no-highlight">513</i>&nbsp;    }
<i class="no-highlight">514</i>&nbsp;
<i class="no-highlight">515</i>&nbsp;    // Related web posts are as following:
<i class="no-highlight">516</i>&nbsp;    // https://stackoverflow.com/questions/53690299/int96value-to-date-string
<i class="no-highlight">517</i>&nbsp;    // https://stackoverflow.com/questions/53103762/cast-int96-timestamp-from-parquet-to-golang/53104516#53104516
<i class="no-highlight">518</i>&nbsp;    private static String int96ToTimestamp(BigInteger int96Value, String dateTimeFormat) {
<i class="no-highlight">519</i>&nbsp;        // Align the byte array to the left of the array size 12
<b class="nc"><i class="no-highlight">520</i>&nbsp;        byte[] bytes = int96Value.toByteArray();</b>
<b class="nc"><i class="no-highlight">521</i>&nbsp;        if (bytes.length &gt; MAX_INT96_BYTES) {</b>
<b class="nc"><i class="no-highlight">522</i>&nbsp;            throw new SnapDataException(ERR_INT96_TOO_LARGE)</b>
<b class="nc"><i class="no-highlight">523</i>&nbsp;                    .formatWith(int96Value.toString())</b>
<b class="nc"><i class="no-highlight">524</i>&nbsp;                    .withReason(REASON_INT96_TOO_LARGE)</b>
<b class="nc"><i class="no-highlight">525</i>&nbsp;                    .withResolution(RESOLUTION_ADDRESS_ISSUE);</b>
<i class="no-highlight">526</i>&nbsp;        }
<b class="nc"><i class="no-highlight">527</i>&nbsp;        int length = Math.min(bytes.length, MAX_INT96_BYTES);</b>
<b class="nc"><i class="no-highlight">528</i>&nbsp;        byte[] int96Bytes = new byte[MAX_INT96_BYTES];</b>
<b class="nc"><i class="no-highlight">529</i>&nbsp;        System.arraycopy(bytes, 0, int96Bytes, MAX_INT96_BYTES - length, length);</b>
<i class="no-highlight">530</i>&nbsp;        // Find Julian day
<b class="nc"><i class="no-highlight">531</i>&nbsp;        int julianDay = 0;</b>
<b class="nc"><i class="no-highlight">532</i>&nbsp;        int index = int96Bytes.length;</b>
<b class="nc"><i class="no-highlight">533</i>&nbsp;        while (index &gt; 8) {</b>
<b class="nc"><i class="no-highlight">534</i>&nbsp;            index--;</b>
<b class="nc"><i class="no-highlight">535</i>&nbsp;            julianDay &lt;&lt;= 8;</b>
<b class="nc"><i class="no-highlight">536</i>&nbsp;            julianDay += int96Bytes[index] &amp; 0xFF;</b>
<i class="no-highlight">537</i>&nbsp;        }
<i class="no-highlight">538</i>&nbsp;        // Find nanoseconds
<b class="nc"><i class="no-highlight">539</i>&nbsp;        long nanos = 0;</b>
<i class="no-highlight">540</i>&nbsp;        // Continue from the index we got to
<b class="nc"><i class="no-highlight">541</i>&nbsp;        while (index &gt; 0) {</b>
<b class="nc"><i class="no-highlight">542</i>&nbsp;            index--;</b>
<b class="nc"><i class="no-highlight">543</i>&nbsp;            nanos &lt;&lt;= 8;</b>
<b class="nc"><i class="no-highlight">544</i>&nbsp;            nanos += int96Bytes[index] &amp; 0xFF;</b>
<i class="no-highlight">545</i>&nbsp;        }
<i class="no-highlight">546</i>&nbsp;        // Get date/time with time zone
<b class="nc"><i class="no-highlight">547</i>&nbsp;        OffsetDateTime offsetDateTime = OffsetDateTime.MIN</b>
<b class="nc"><i class="no-highlight">548</i>&nbsp;                .with(JulianFields.JULIAN_DAY, julianDay)</b>
<b class="nc"><i class="no-highlight">549</i>&nbsp;                .plusNanos(nanos)</b>
<b class="nc"><i class="no-highlight">550</i>&nbsp;                .withOffsetSameLocal(ZoneOffset.UTC);</b>
<b class="nc"><i class="no-highlight">551</i>&nbsp;        return offsetDateTime.format(DateTimeFormatter.ofPattern(</b>
<b class="nc"><i class="no-highlight">552</i>&nbsp;                StringUtils.isBlank(dateTimeFormat) ? DEFAULT_DATE_TIME_FORMAT : dateTimeFormat));</b>
<i class="no-highlight">553</i>&nbsp;    }
<i class="no-highlight">554</i>&nbsp;}
</div>
</pre>
</div>

<script type="text/javascript">
(function() {
    var msie = false, msie9 = false;
    /*@cc_on
      msie = true;
      @if (@_jscript_version >= 9)
        msie9 = true;
      @end
    @*/

    if (!msie || msie && msie9) {
        var codeBlock = document.getElementById('sourceCode');

        if (codeBlock) {
            hljs.highlightBlock(codeBlock);
        }
    }
})();
</script>

<div class="footer">
    
    <div style="float:right;">generated on 2024-01-19 15:49</div>
</div>
</body>
</html>
